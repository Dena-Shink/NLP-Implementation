
"""
Test script for medical summary tools.
Tests various medical NLP tools with sample medical text and evaluates their performance.
"""

import json
import time
import sys
import argparse
import re
import os
from urllib.parse import urlparse
from datetime import datetime
from typing import Dict, List, Any, Optional, Tuple
import traceback

# Sample medical text for testing
SAMPLE_MEDICAL_TEXT = """
Patient presents with chest pain and shortness of breath. 
History of hypertension and diabetes mellitus type 2.
Blood pressure: 150/95 mmHg. Heart rate: 88 bpm.
ECG shows ST elevation in leads II, III, and aVF.
Patient denies nausea or vomiting. No known drug allergies.
Medications: Metformin 500mg twice daily, Lisinopril 10mg daily.
"""

GCS_BUCKET_URL_PLACEHOLDER = "YOUR_GCS_BUCKET_URL_HERE"

class ToolTester:
    """Base class for testing medical NLP tools."""
    
    def __init__(self, tool_name: str):
        self.tool_name = tool_name
        self.require_model_summary = False
        self.supports_model_summary = False
        self.results = {
            'tool_name': tool_name,
            'status': 'not_tested',
            'error': None,
            'execution_time': None,
            'capabilities': [],
            'entities_found': [],
            'raw_model_output': None,
            'notes': [],
            'summary': None,
            'summary_source': 'fallback',
        }
    
    def test(self, text: str) -> Dict[str, Any]:
        """Test the tool with given text."""
        start_time = time.time()
        try:
            result = self._run_test(text)
            self.results['execution_time'] = time.time() - start_time
            if self.results['status'] == 'not_tested':
                self.results['status'] = 'success'
            if self.require_model_summary and self.results.get('status') == 'success':
                if not self.results.get('summary') or self.results.get('summary_source') != 'model':
                    self.results['status'] = 'error'
                    self.results['error'] = 'Model summary was not generated by this tester'
                    self.results['notes'].append('Model summary enforcement failed: summary_source must be model')
                    self.results['summary'] = (
                        f"{self.tool_name} did not return a model-generated summary. "
                        "Check model execution path and summary assignment."
                    )
                    self.results['summary_source'] = 'model_enforcement_error'
            if self.results.get('summary_source') == 'model' and self.results.get('raw_model_output') is not None:
                self.results['summary'] = append_full_raw_output_to_summary(
                    self.results.get('summary'),
                    self.results.get('raw_model_output'),
                )
            if (not self.results.get('summary')) or ('Run status: not_tested' in str(self.results.get('summary'))):
                self.results['summary'] = generate_verbose_summary(
                    text,
                    self.tool_name,
                    self.results.get('status'),
                    self.results.get('capabilities', []),
                    self.results.get('entities_found', []),
                    self.results.get('notes', []),
                )
                self.results['summary_source'] = 'fallback'
            return result
        except Exception as e:
            self.results['execution_time'] = time.time() - start_time
            self.results['status'] = 'error'
            self.results['error'] = str(e)
            self.results['notes'].append(f"Error: {traceback.format_exc()}")
            if self.require_model_summary:
                self.results['summary'] = (
                    f"{self.tool_name} model execution failed before summary generation: {str(e)}"
                )
                self.results['summary_source'] = 'model_error'
                return self.results
            self.results['summary'] = generate_verbose_summary(
                text,
                self.tool_name,
                self.results.get('status'),
                self.results.get('capabilities', []),
                self.results.get('entities_found', []),
                self.results.get('notes', []),
            )
            self.results['summary_source'] = 'fallback'
            return self.results
    
    def _run_test(self, text: str) -> Dict[str, Any]:
        """Override in subclasses to implement specific tool testing."""
        raise NotImplementedError


class MedSpaCyTester(ToolTester):
    """Test MedSpaCy tool."""

    def __init__(self, tool_name: str):
        super().__init__(tool_name)
        self.require_model_summary = True
        self.supports_model_summary = True
    
    def _run_test(self, text: str) -> Dict[str, Any]:
        try:
            import spacy
            import medspacy
            import logging
            
            # Suppress debug logging
            logging.getLogger("PyRuSH").setLevel(logging.WARNING)
            
            # Load MedSpaCy with default components
            nlp = medspacy.load()

            enable_test_ruler = os.getenv('MEDSPACY_ENABLE_TEST_RULER', '0').strip() == '1'
            if enable_test_ruler and 'entity_ruler' not in nlp.pipe_names:
                ruler = nlp.add_pipe('entity_ruler', before='medspacy_context' if 'medspacy_context' in nlp.pipe_names else None)
                ruler.add_patterns([
                    {'label': 'PROBLEM', 'pattern': 'chest pain'},
                    {'label': 'PROBLEM', 'pattern': 'shortness of breath'},
                    {'label': 'PROBLEM', 'pattern': 'hypertension'},
                    {'label': 'PROBLEM', 'pattern': 'diabetes mellitus type 2'},
                    {'label': 'FINDING', 'pattern': 'ST elevation'},
                    {'label': 'OBSERVATION', 'pattern': 'blood pressure'},
                    {'label': 'OBSERVATION', 'pattern': 'heart rate'},
                    {'label': 'MEDICATION', 'pattern': 'Metformin'},
                    {'label': 'MEDICATION', 'pattern': 'Lisinopril'},
                ])

            doc = nlp(text)
            
            entities = []
            for ent in doc.ents:
                entities.append({
                    'text': ent.text,
                    'label': ent.label_,
                    'start': ent.start_char,
                    'end': ent.end_char
                })
            
            # Check for target matcher entities (if target matcher is enabled)
            if 'medspacy_target_matcher' in nlp.component_names:
                # Target matcher may find additional entities
                target_matcher = nlp.get_pipe('medspacy_target_matcher')
                # Entities are already in doc.ents if target matcher found them
            
            # Check for context (negation, etc.)
            context_entities = []
            if 'medspacy_context' in nlp.component_names:
                for ent in doc.ents:
                    if hasattr(ent._, 'is_negated'):
                        context_entities.append({
                            'text': ent.text,
                            'is_negated': ent._.is_negated,
                            'is_uncertain': getattr(ent._, 'is_uncertain', False),
                            'is_historical': getattr(ent._, 'is_historical', False),
                            'is_hypothetical': getattr(ent._, 'is_hypothetical', False)
                        })
            
            # Also check for custom attributes if available
            if hasattr(doc, '_.medspacy_pyrush'):
                self.results['notes'].append("PyRuSH sentence segmentation enabled")
            
            self.results['entities_found'] = entities
            self.results['raw_model_output'] = {
                'model_type': 'medspacy',
                'component_names': list(nlp.component_names),
                'doc_entities': entities,
                'context_entities': context_entities,
            }
            if context_entities:
                self.results['notes'].append(f"Context analysis: {len(context_entities)} entities with context")
            
            self.results['capabilities'] = [
                'Named Entity Recognition (NER)',
                'Clinical concept extraction',
                'Temporal information extraction',
                'Contextual analysis (negation, uncertainty)',
                'Sentence segmentation (PyRuSH)',
                'Target matching'
            ]
            self.results['notes'].append(f"Found {len(entities)} entities")
            self.results['notes'].append(f"Components enabled: {', '.join(nlp.component_names)}")
            unique_labels = sorted({ent.get('label', '') for ent in entities if ent.get('label')})
            negated_count = sum(1 for item in context_entities if item.get('is_negated'))
            uncertain_count = sum(1 for item in context_entities if item.get('is_uncertain'))
            historical_count = sum(1 for item in context_entities if item.get('is_historical'))
            component_list = ", ".join(nlp.component_names)
            problems = [ent['text'] for ent in entities if ent.get('label') == 'PROBLEM']
            findings = [ent['text'] for ent in entities if ent.get('label') == 'FINDING']
            medications = [ent['text'] for ent in entities if ent.get('label') == 'MEDICATION']

            problem_text = ", ".join(problems) if problems else "none detected"
            finding_text = ", ".join(findings) if findings else "none detected"
            medication_text = ", ".join(medications) if medications else "none detected"
            self.results['summary'] = (
                f"MedSpaCy clinical summary: problems={problem_text}. "
                f"Findings={finding_text}. Medications={medication_text}. "
                f"Context review: negated={negated_count}, uncertain={uncertain_count}, historical={historical_count}. "
                f"Pipeline used: {component_list}. Total labeled entities={len(entities)}"
                f"{f' ({', '.join(unique_labels)})' if unique_labels else ''}."
            )
            self.results['summary_source'] = 'model'
            return self.results
        except ImportError:
            self.results['status'] = 'not_installed'
            self.results['notes'].append("MedSpaCy not installed. Install with: pip install medspacy")
            return self.results


class ScispaCyTester(ToolTester):
    """Test ScispaCy tool."""

    def __init__(self, tool_name: str):
        super().__init__(tool_name)
        self.require_model_summary = True
        self.supports_model_summary = True
    
    def _run_test(self, text: str) -> Dict[str, Any]:
        try:
            import scispacy
            import spacy
            
            nlp = spacy.load("en_core_sci_sm")
            doc = nlp(text)
            
            entities = []
            for ent in doc.ents:
                entities.append({
                    'text': ent.text,
                    'label': ent.label_,
                    'start': ent.start_char,
                    'end': ent.end_char
                })
            
            self.results['entities_found'] = entities
            self.results['raw_model_output'] = {
                'model_type': 'scispacy',
                'model_name': 'en_core_sci_sm',
                'doc_entities': entities,
                'entity_count': len(entities),
            }
            self.results['capabilities'] = [
                'Biomedical NER',
                'Entity linking to UMLS',
                'Abbreviation detection',
                'Scientific text processing'
            ]
            self.results['notes'].append(f"Found {len(entities)} entities")
            label_counts: Dict[str, int] = {}
            for ent in entities:
                label = ent.get('label', 'UNKNOWN')
                label_counts[label] = label_counts.get(label, 0) + 1

            top_labels = sorted(label_counts.items(), key=lambda item: item[1], reverse=True)[:5]
            top_label_text = ", ".join([f"{label}={count}" for label, count in top_labels]) if top_labels else "none"
            preview_entities = [ent.get('text', '') for ent in entities[:8] if ent.get('text')]
            unique_preview = []
            seen = set()
            for ent_text in preview_entities:
                normalized = ent_text.lower().strip()
                if normalized and normalized not in seen:
                    seen.add(normalized)
                    unique_preview.append(ent_text)
            preview_text = ", ".join(unique_preview) if unique_preview else "no entities extracted"

            self.results['summary'] = (
                f"ScispaCy biomedical summary: key spans identified -> {preview_text}. "
                f"Model en_core_sci_sm detected {len(entities)} entities with label profile [{top_label_text}]. "
                f"This output emphasizes scientific/biomedical term spotting rather than rule-based clinical context."
            )
            self.results['summary_source'] = 'model'
            return self.results
        except ImportError:
            self.results['status'] = 'not_installed'
            self.results['notes'].append("ScispaCy not installed. Install with: pip install scispacy")
            return self.results
        except OSError:
            self.results['status'] = 'model_not_found'
            self.results['notes'].append("Model not found. Download with: python -m spacy download en_core_sci_sm")
            return self.results


class QuickUMLSTester(ToolTester):
    """Test QuickUMLS tool."""
    
    def _run_test(self, text: str) -> Dict[str, Any]:
        try:
            from quickumls import QuickUMLS

            quickumls_fp = (
                os.getenv('QUICKUMLS_FP')
                or os.getenv('QUICKUMLS_PATH')
                or ''
            ).strip()
            if not quickumls_fp:
                self.results['status'] = 'configuration_needed'
                self.results['notes'].append(
                    'Set QUICKUMLS_FP (or QUICKUMLS_PATH) to your QuickUMLS data directory to run this tester.'
                )
                return self.results

            matcher = QuickUMLS(quickumls_fp=quickumls_fp)
            matches = matcher.match(text, best_match=True, ignore_syntax=False)
            
            entities = []
            for match in matches:
                for m in match:
                    entities.append({
                        'text': m['term'],
                        'cui': m['cui'],
                        'similarity': m['similarity'],
                        'semtypes': m['semtypes']
                    })
            
            self.results['entities_found'] = entities
            self.results['raw_model_output'] = {
                'model_type': 'quickumls',
                'quickumls_fp': quickumls_fp,
                'matches': matches,
                'flattened_entities': entities,
                'match_group_count': len(matches),
            }
            self.results['capabilities'] = [
                'UMLS concept matching',
                'Semantic type identification',
                'Concept normalization',
                'Fuzzy matching'
            ]
            self.results['notes'].append(f"Found {len(entities)} UMLS concepts")
            self.results['summary'] = (
                f"QuickUMLS concept summary: matched {len(entities)} concepts in {len(matches)} match groups "
                f"using data path {quickumls_fp}."
            )
            self.results['summary_source'] = 'model'
            return self.results
        except ImportError:
            self.results['status'] = 'not_installed'
            self.results['notes'].append("QuickUMLS not installed. Install with: pip install quickumls")
            return self.results
        except Exception as e:
            self.results['status'] = 'configuration_needed'
            self.results['notes'].append(f"Requires UMLS data installation: {str(e)}")
            return self.results


class CLiNERTester(ToolTester):
    """Test CLiNER tool."""
    
    def _run_test(self, text: str) -> Dict[str, Any]:
        try:
            from cliner.cli import predict
            
            # CLiNER requires model files and specific input format
            # This is a placeholder implementation
            self.results['capabilities'] = [
                'Clinical NER',
                'Concept extraction',
                'Medical concept identification'
            ]
            self.results['status'] = 'configuration_needed'
            self.results['notes'].append("CLiNER requires model files and specific setup. See: https://github.com/text-machine-lab/cliner")
            return self.results
        except ImportError:
            self.results['status'] = 'not_installed'
            self.results['notes'].append("CLiNER not installed. Install from: https://github.com/text-machine-lab/cliner")
            return self.results


class SparkNLPTester(ToolTester):
    """Test Spark NLP for Healthcare."""
    
    def _run_test(self, text: str) -> Dict[str, Any]:
        try:
            from sparknlp import start
            from sparknlp.pretrained import PretrainedPipeline
            
            spark = start()
            pipeline = PretrainedPipeline("recognize_entities_dl", lang="en")
            result = pipeline.annotate(text)
            
            entities = result.get('entities', [])
            self.results['entities_found'] = entities
            self.results['capabilities'] = [
                'Healthcare NER',
                'Clinical entity recognition',
                'Relation extraction',
                'De-identification',
                'Clinical coding'
            ]
            self.results['notes'].append(f"Found {len(entities)} entities")
            return self.results
        except ImportError:
            self.results['status'] = 'not_installed'
            self.results['notes'].append("Spark NLP not installed. Requires Java and Spark. Install with: pip install spark-nlp")
            return self.results
        except Exception as e:
            self.results['status'] = 'configuration_needed'
            self.results['notes'].append(f"Requires Spark and Java setup: {str(e)}")
            return self.results


class OpenMedTester(ToolTester):
    """Test OpenMed tool."""

    def __init__(self, tool_name: str):
        super().__init__(tool_name)
        self.supports_model_summary = True
    
    def _run_test(self, text: str) -> Dict[str, Any]:
        try:
            import openmed

            generated_summary = None
            try:
                if hasattr(openmed, 'summarize_text'):
                    summary_result = openmed.summarize_text(text)
                    if isinstance(summary_result, str) and summary_result.strip():
                        generated_summary = summary_result.strip()
                    elif isinstance(summary_result, dict):
                        generated_summary = str(
                            summary_result.get('summary')
                            or summary_result.get('text')
                            or ''
                        ).strip() or None
            except Exception as summary_error:
                self.results['notes'].append(f"Summary API unavailable: {str(summary_error)[:80]}")
            
            # Try to use analyze_text or extract_pii
            entities = []
            pipeline_entities = []
            try:
                # Try PII extraction first
                pii_result = openmed.extract_pii(text)
                if pii_result and isinstance(pii_result, list):
                    entities = [{'text': str(e), 'type': 'PII'} for e in pii_result[:10]]  # Limit to first 10
                    self.results['notes'].append("Used extract_pii function")
                elif hasattr(pii_result, 'entities'):
                    entities = pii_result.entities
            except Exception as e1:
                try:
                    # Try analyze_text
                    result = openmed.analyze_text(text)
                    if result and isinstance(result, dict):
                        if 'entities' in result:
                            entities = result['entities']
                        elif 'predictions' in result:
                            entities = result['predictions']
                except Exception as e2:
                    self.results['notes'].append(f"Tried multiple APIs. Errors: {str(e1)[:50]}, {str(e2)[:50]}")

            if not generated_summary and not entities:
                try:
                    from transformers import pipeline

                    ner = pipeline(
                        "token-classification",
                        model="d4data/biomedical-ner-all",
                        aggregation_strategy="simple",
                    )
                    pipeline_entities = ner(text)
                    entities = [
                        {
                            'text': item.get('word', ''),
                            'type': item.get('entity_group', 'ENTITY'),
                            'score': float(item.get('score', 0.0)),
                            'start': item.get('start'),
                            'end': item.get('end'),
                        }
                        for item in pipeline_entities
                    ]
                    self.results['notes'].append("Used transformers biomedical NER fallback (d4data/biomedical-ner-all)")
                except Exception as pipeline_error:
                    self.results['notes'].append(f"Transformers fallback failed: {str(pipeline_error)[:140]}")
            
            self.results['entities_found'] = entities
            self.results['raw_model_output'] = {
                'model_type': 'openmed',
                'generated_summary': generated_summary,
                'entities': entities,
                'pipeline_entities': pipeline_entities,
            }
            self.results['capabilities'] = [
                'Medical NER (12+ specialized models)',
                'HIPAA-compliant PII detection',
                'Entity extraction',
                'De-identification',
                'Batch processing',
                'Text summarization'
            ]
            if generated_summary:
                self.results['summary'] = generated_summary
                self.results['summary_source'] = 'model'
            elif entities:
                preview = ", ".join([str(e)[:80] for e in entities[:8]])
                self.results['summary'] = (
                    f"OpenMed extraction summary: {len(entities)} entities returned. Preview: {preview}"
                )
                self.results['summary_source'] = 'model'
            self.results['notes'].append(f"Found {len(entities)} entities")
            if len(entities) == 0:
                self.results['notes'].append("Note: OpenMed may need model loading or transformers library")
            return self.results
        except ImportError:
            self.results['status'] = 'not_installed'
            self.results['notes'].append("OpenMed not installed. Install with: pip install openmed")
            return self.results
        except Exception as e:
            self.results['status'] = 'error'
            self.results['notes'].append(f"Error using OpenMed: {str(e)[:100]}")
            return self.results


class MedTextTester(ToolTester):
    """Test MedText tool."""
    
    def _run_test(self, text: str) -> Dict[str, Any]:
        try:
            import medtext

            available = [name for name in dir(medtext) if not name.startswith('_')]
            extracted = None
            generated_summary = None

            if hasattr(medtext, 'summarize') and callable(getattr(medtext, 'summarize')):
                try:
                    generated_summary = medtext.summarize(text)
                except Exception as summary_error:
                    self.results['notes'].append(f"medtext.summarize failed: {str(summary_error)[:120]}")

            if hasattr(medtext, 'analyze') and callable(getattr(medtext, 'analyze')):
                try:
                    extracted = medtext.analyze(text)
                except Exception as analyze_error:
                    self.results['notes'].append(f"medtext.analyze failed: {str(analyze_error)[:120]}")

            self.results['capabilities'] = [
                'Clinical text analysis',
                'High-performance processing',
                'Full documentation support',
                'Text summarization'
            ]
            self.results['raw_model_output'] = {
                'model_type': 'medtext',
                'module_attributes_sample': available[:60],
                'summary_output': generated_summary,
                'analysis_output': extracted,
            }

            if generated_summary is not None:
                summary_str = generated_summary if isinstance(generated_summary, str) else json.dumps(generated_summary, default=str)
                self.results['summary'] = f"MedText summary output: {summary_str[:2000]}"
                self.results['summary_source'] = 'model'
                self.results['notes'].append("Used medtext.summarize")
            elif extracted is not None:
                analysis_str = extracted if isinstance(extracted, str) else json.dumps(extracted, default=str)
                self.results['summary'] = f"MedText analysis output: {analysis_str[:2000]}"
                self.results['summary_source'] = 'model'
                self.results['notes'].append("Used medtext.analyze")
            else:
                self.results['status'] = 'configuration_needed'
                self.results['notes'].append("MedText import succeeded but no callable summarize/analyze API produced output.")
            return self.results
        except ImportError:
            self.results['status'] = 'not_installed'
            self.results['notes'].append("MedText not installed. Install with: pip install medtext")
            return self.results
        except Exception as e:
            self.results['status'] = 'error'
            self.results['notes'].append(f"Error using MedText: {str(e)}")
            return self.results


class GenericTester(ToolTester):
    """Generic tester for tools that require special setup or APIs."""
    
    def __init__(self, tool_name: str, capabilities: List[str], setup_notes: str):
        super().__init__(tool_name)
        self.capabilities = capabilities
        self.setup_notes = setup_notes
    
    def _run_test(self, text: str) -> Dict[str, Any]:
        self.results['capabilities'] = self.capabilities
        self.results['status'] = 'manual_setup_required'
        self.results['notes'].append(self.setup_notes)
        return self.results


def generate_extractive_summary(text: str, max_sentences: int = 5) -> str:
    """Generate a lightweight extractive summary from input text."""
    cleaned = (text or "").strip()
    if not cleaned:
        return ""

    sentences = [s.strip() for s in re.split(r'(?<=[.!?])\s+', cleaned) if s.strip()]
    if len(sentences) <= max_sentences:
        return " ".join(sentences)

    keywords = {
        'patient', 'history', 'diagnosis', 'assessment', 'plan', 'medication',
        'blood pressure', 'heart rate', 'ecg', 'pain', 'diabetes', 'hypertension'
    }

    scored_sentences = []
    for index, sentence in enumerate(sentences):
        sentence_lower = sentence.lower()
        keyword_score = sum(1 for keyword in keywords if keyword in sentence_lower)
        length_score = 1 if 30 <= len(sentence) <= 220 else 0
        position_score = 2 if index == 0 else (1 if index < 4 else 0)
        total_score = keyword_score + length_score + position_score
        scored_sentences.append((total_score, index, sentence))

    top = sorted(scored_sentences, key=lambda item: (-item[0], item[1]))[:max_sentences]
    ordered = [sentence for _, _, sentence in sorted(top, key=lambda item: item[1])]
    return " ".join(ordered)


def generate_verbose_summary(
    text: str,
    tool_name: str,
    status: Optional[str],
    capabilities: Optional[List[str]] = None,
    entities_found: Optional[List[Any]] = None,
    notes: Optional[List[str]] = None,
) -> str:
    """Create a verbose, structured summary from clinical text for each tool."""
    cleaned = (text or "").strip()
    if not cleaned:
        return f"{tool_name} ({status or 'unknown'}): No input text available for summarization."

    sentences = [s.strip() for s in re.split(r'(?<=[.!?])\s+', cleaned) if s.strip()]
    concise = generate_extractive_summary(cleaned, max_sentences=6)

    medications = []
    med_match = re.search(r'(?i)medications?\s*:\s*([^\n\.]+)', cleaned)
    if med_match:
        medications = [m.strip() for m in re.split(r',|;| and ', med_match.group(1)) if m.strip()]

    vitals = re.findall(r'(?i)(blood pressure\s*[:=]?\s*[^\n\.]+|heart rate\s*[:=]?\s*[^\n\.]+|bp\s*[:=]?\s*[^\n\.]+)', cleaned)
    key_conditions = []
    for keyword in ['chest pain', 'shortness of breath', 'hypertension', 'diabetes', 'ecg', 'st elevation', 'allerg']:
        if keyword in cleaned.lower():
            key_conditions.append(keyword)

    capabilities = capabilities or []
    entities_found = entities_found or []
    notes = notes or []

    focus_by_tool = {
        'MedSpaCy': 'clinical entity and context extraction (negation/uncertainty focus)',
        'ScispaCy': 'biomedical entity detection and linking focus',
        'QuickUMLS': 'UMLS concept normalization focus',
        'CLiNER': 'clinical named-entity extraction focus',
        'Spark NLP for Healthcare': 'healthcare pipeline extraction focus',
        'OpenMed': 'de-identification and medical extraction focus',
        'MedText': 'clinical text understanding and summarization focus',
        'Apache cTakes': 'clinical pipeline and temporal concept focus',
        'MetaMap': 'UMLS terminology mapping focus',
        'CLAMP': 'clinical relation and timeline extraction focus',
        'NegEx': 'negation detection focus',
        'MedEx': 'medication extraction focus',
        'SemRep': 'semantic relation extraction focus',
        'Bio-Concept Annotator': 'biomedical concept annotation focus',
        'HITEx': 'clinical document extraction focus',
        'cTakes timeline plugin': 'temporal timeline construction focus',
        'Phitler': 'PHI detection and de-identification focus',
    }

    tool_focus = focus_by_tool.get(tool_name, 'general clinical summarization focus')

    summary_parts = [
        f"Tool: {tool_name}",
        f"Run status: {status or 'unknown'}.",
        f"Model focus: {tool_focus}.",
        f"Clinical overview: {concise}",
    ]

    if key_conditions:
        summary_parts.append(f"Key findings detected: {', '.join(key_conditions)}.")
    if vitals:
        summary_parts.append(f"Vital signs mentioned: {'; '.join(vitals)}.")
    if medications:
        summary_parts.append(f"Medications captured: {', '.join(medications)}.")

    if capabilities:
        summary_parts.append(f"Configured capabilities: {', '.join(capabilities[:4])}{'...' if len(capabilities) > 4 else ''}.")

    summary_parts.append(f"Extracted entity count from this tool: {len(entities_found)}.")

    if notes:
        summary_parts.append(f"Tool notes snapshot: {notes[0][:140]}.")

    summary_parts.append(f"Document size: {len(cleaned)} characters across approximately {len(sentences)} sentences.")
    summary_parts.append("Interpretation: This summary is generated from extracted text and should be reviewed for clinical accuracy.")
    return " ".join(summary_parts)


def append_full_raw_output_to_summary(summary: Any, raw_model_output: Any) -> str:
    """Append full raw model output JSON to summary text for maximum transparency."""
    summary_text = str(summary) if summary is not None else ""
    try:
        raw_text = json.dumps(raw_model_output, indent=2, ensure_ascii=False, default=str)
    except Exception:
        raw_text = str(raw_model_output)
    return f"{summary_text}\n\nRaw model output (full):\n{raw_text}"


def extract_text_from_pdf(pdf_path: str) -> str:
    """Extract text from a local PDF file."""
    try:
        from pypdf import PdfReader
    except ImportError as exc:
        raise ImportError(
            "pypdf is required for PDF input. Install with: pip install pypdf"
        ) from exc

    try:
        reader = PdfReader(pdf_path)
        extracted_pages = []
        for page in reader.pages:
            page_text = page.extract_text() or ""
            extracted_pages.append(page_text)

        text = "\n".join(extracted_pages).strip()
        if not text:
            raise ValueError(f"No extractable text found in PDF: {pdf_path}")

        return text
    except FileNotFoundError as exc:
        raise FileNotFoundError(f"PDF file not found: {pdf_path}") from exc
    except Exception as exc:
        raise RuntimeError(f"Failed to read PDF '{pdf_path}': {exc}") from exc


def extract_text_from_text_file(text_file_path: str) -> str:
    """Extract text from a plain text file."""
    try:
        with open(text_file_path, 'r', encoding='utf-8') as f:
            text = f.read().strip()
        if not text:
            raise ValueError(f"No text found in file: {text_file_path}")
        return text
    except FileNotFoundError as exc:
        raise FileNotFoundError(f"Text file not found: {text_file_path}") from exc
    except Exception as exc:
        raise RuntimeError(f"Failed to read text file '{text_file_path}': {exc}") from exc


def parse_gcs_bucket_url(bucket_url: str) -> Tuple[str, str]:
    """Parse GCS URL into (bucket_name, prefix). Supports gs:// and storage.googleapis.com URLs."""
    cleaned = (bucket_url or "").strip()
    if not cleaned:
        raise ValueError("GCS bucket URL is empty")

    if cleaned.startswith("gs://"):
        without_scheme = cleaned[len("gs://"):].strip("/")
        parts = without_scheme.split("/", 1)
        bucket_name = parts[0]
        prefix = parts[1] if len(parts) > 1 else ""
        if not bucket_name:
            raise ValueError(f"Invalid gs:// URL: {bucket_url}")
        return bucket_name, prefix

    parsed = urlparse(cleaned)
    host = (parsed.netloc or "").lower()
    path = (parsed.path or "").lstrip("/")
    if host in {"storage.googleapis.com", "www.storage.googleapis.com"}:
        parts = path.split("/", 1)
        if not parts or not parts[0]:
            raise ValueError(f"Invalid GCS URL: {bucket_url}")
        bucket_name = parts[0]
        prefix = parts[1] if len(parts) > 1 else ""
        return bucket_name, prefix

    raise ValueError(
        "Unsupported bucket URL format. Use gs://bucket/prefix or https://storage.googleapis.com/bucket/prefix"
    )


def download_pdfs_from_gcs(
    bucket_url: str,
    local_dir: str,
    max_files: int = 20,
) -> List[str]:
    """Download PDF files from a GCS bucket URL and return local file paths."""
    try:
        from google.cloud import storage
    except ImportError as exc:
        raise ImportError(
            "google-cloud-storage is required for bucket ingestion. Install with: pip install google-cloud-storage"
        ) from exc

    bucket_name, prefix = parse_gcs_bucket_url(bucket_url)
    os.makedirs(local_dir, exist_ok=True)

    client = storage.Client()
    bucket = client.bucket(bucket_name)

    downloaded_files: List[str] = []
    for blob in client.list_blobs(bucket, prefix=prefix):
        blob_name = blob.name or ""
        if not blob_name.lower().endswith(".pdf"):
            continue

        file_name = os.path.basename(blob_name) or f"file_{len(downloaded_files)+1}.pdf"
        local_path = os.path.join(local_dir, file_name)
        blob.download_to_filename(local_path)
        downloaded_files.append(local_path)

        if len(downloaded_files) >= max_files:
            break

    return downloaded_files


def run_bucket_pipeline(
    bucket_url: str,
    output_file: str,
    profile: str,
    strict_model_summaries: bool,
    local_dir: str,
    max_files: int,
) -> str:
    """Run model testing for PDFs downloaded from GCS and save aggregate report."""
    downloaded = download_pdfs_from_gcs(bucket_url, local_dir=local_dir, max_files=max_files)
    if not downloaded:
        raise RuntimeError("No PDF files found in the provided GCS bucket URL/prefix")

    per_file_results: List[Dict[str, Any]] = []
    for pdf_path in downloaded:
        text_to_test = extract_text_from_pdf(pdf_path)
        results = test_all_tools(
            text_to_test,
            profile=profile,
            strict_model_summaries=strict_model_summaries,
        )
        per_file_results.append(
            {
                'source_pdf': pdf_path,
                'input_text_length': len(text_to_test),
                'results': results,
            }
        )

    aggregate = {
        'test_date': datetime.now().isoformat(),
        'pipeline': 'gcs_bucket_pdf_processing',
        'bucket_url': bucket_url,
        'downloaded_files_count': len(downloaded),
        'downloaded_files': downloaded,
        'profile': profile,
        'strict_model_summaries': strict_model_summaries,
        'per_file_results': per_file_results,
    }

    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(aggregate, f, indent=2)

    return output_file


def test_all_tools(
    text: str,
    profile: str = "python",
    strict_model_summaries: bool = False,
) -> List[Dict[str, Any]]:
    """Test all medical tools with the given text."""
    full_testers = [
        MedSpaCyTester("MedSpaCy"),
        OpenMedTester("OpenMed"),
        ScispaCyTester("ScispaCy"),
        MedTextTester("MedText"),
        QuickUMLSTester("QuickUMLS"),
        CLiNERTester("CLiNER"),
        SparkNLPTester("Spark NLP for Healthcare"),
        GenericTester(
            "Apache cTakes",
            [
                'Clinical concept extraction',
                'UMLS mapping',
                'Temporal information',
                'Negation detection'
            ],
            "Apache cTakes is a Java-based tool. Requires Java installation and cTakes setup. See: https://ctakes.apache.org/"
        ),
        GenericTester(
            "MetaMap",
            [
                'UMLS concept mapping',
                'Semantic type identification',
                'Concept normalization',
                'Medical terminology mapping'
            ],
            "MetaMap requires UMLS license and installation. See: https://metamap.nlm.nih.gov/"
        ),
        GenericTester(
            "CLAMP",
            [
                'Clinical NLP pipeline',
                'NER and relation extraction',
                'UMLS mapping',
                'Temporal information extraction'
            ],
            "CLAMP is a Java-based tool. Requires Java and CLAMP installation. See: https://clamp.uth.edu/"
        ),
        GenericTester(
            "NegEx",
            [
                'Negation detection',
                'Negation scope identification',
                'Clinical negation patterns'
            ],
            "NegEx is a negation detection algorithm. Can be used standalone or integrated with other tools."
        ),
        GenericTester(
            "MedEx",
            [
                'Medication extraction',
                'Drug name recognition',
                'Dosage and frequency extraction'
            ],
            "MedEx focuses on medication extraction. See: https://github.com/medex-group/medex"
        ),
        GenericTester(
            "SemRep",
            [
                'Semantic relation extraction',
                'Predication extraction',
                'UMLS-based semantic processing'
            ],
            "SemRep requires UMLS license and installation. See: https://semrep.nlm.nih.gov/"
        ),
        GenericTester(
            "Bio-Concept Annotator",
            [
                'Biomedical concept annotation',
                'UMLS concept mapping',
                'Entity recognition'
            ],
            "Bio-Concept Annotator is a web service. Requires API access or local installation."
        ),
        GenericTester(
            "HITEx",
            [
                'Clinical information extraction',
                'Temporal information',
                'Problem list extraction'
            ],
            "HITEx is a Java-based tool. Requires Java and HITEx setup."
        ),
        GenericTester(
            "cTakes timeline plugin",
            [
                'Temporal information extraction',
                'Event timeline construction',
                'Time expression recognition'
            ],
            "cTakes timeline plugin extends Apache cTakes. Requires cTakes installation."
        ),
        GenericTester(
            "Phitler",
            [
                'Protected Health Information (PHI) detection',
                'De-identification',
                'Privacy protection'
            ],
            "Phitler is used for PHI detection and de-identification. See relevant documentation for setup."
        ),
    ]

    local_testers = [
        OpenMedTester("OpenMed"),
        MedTextTester("MedText"),
    ]

    python_testers = [
        MedSpaCyTester("MedSpaCy"),
        ScispaCyTester("ScispaCy"),
        OpenMedTester("OpenMed"),
        MedTextTester("MedText"),
        QuickUMLSTester("QuickUMLS"),
        CLiNERTester("CLiNER"),
    ]

    profile_to_testers = {
        "full": full_testers,
        "local": local_testers,
        "python": python_testers,
    }
    testers = profile_to_testers.get(profile, full_testers)

    if strict_model_summaries:
        for tester in testers:
            if getattr(tester, 'supports_model_summary', False):
                tester.require_model_summary = True
    
    results = []
    print(f"\n{'='*60}")
    print(f"Testing {len(testers)} medical NLP tools")
    print(f"{'='*60}\n")
    print(f"Run profile: {profile}")
    print(f"Strict model summaries: {'enabled' if strict_model_summaries else 'disabled'}")
    if profile != "full":
        skipped_count = len(full_testers) - len(testers)
        print(f"Skipping {skipped_count} tools not included in {profile} profile\n")

    for tester in testers:
        print(f"Testing {tester.tool_name}...", end=" ", flush=True)
        result = tester.test(text)
        results.append(result)
        
        if result['status'] == 'success':
            print("✓ Success")
        elif result['status'] == 'not_installed':
            print("✗ Not installed")
        elif result['status'] == 'configuration_needed':
            print("⚠ Configuration needed")
        elif result['status'] == 'manual_setup_required':
            print("ℹ Manual setup required")
        else:
            print(f"✗ Error: {result.get('error', 'Unknown error')}")
    
    return results


def generate_report(
    results: List[Dict[str, Any]],
    output_file: str,
    input_text_length: int,
    input_source: str,
):
    """Generate a JSON report of test results."""
    full_model_output_summary = [
        {
            'tool_name': result.get('tool_name'),
            'status': result.get('status'),
            'summary_source': result.get('summary_source', 'fallback'),
            'summary': result.get('summary'),
        }
        for result in results
    ]

    report = {
        'test_date': datetime.now().isoformat(),
        'input_source': input_source,
        'input_text_length': input_text_length,
        'tools_tested': len(results),
        'full_model_output_summary': full_model_output_summary,
        'raw_model_outputs': [
            {
                'tool_name': result.get('tool_name'),
                'status': result.get('status'),
                'raw_model_output': result.get('raw_model_output'),
            }
            for result in results
            if result.get('raw_model_output') is not None
        ],
        'results': results
    }
    
    with open(output_file, 'w') as f:
        json.dump(report, f, indent=2, default=str)
    
    print(f"\n{'='*60}")
    print(f"Report saved to: {output_file}")
    print(f"{'='*60}\n")


def main():
    """Main function to run all tests."""
    parser = argparse.ArgumentParser(description="Run medical NLP tool tests")
    parser.add_argument(
        "--input-pdf",
        type=str,
        help="Path to a local PDF file to extract text from and test",
    )
    parser.add_argument(
        "--input-text-file",
        type=str,
        help="Path to a local .txt file to use as model input",
    )
    parser.add_argument(
        "--output",
        type=str,
        default="test_results.json",
        help="Output report JSON filename (default: test_results.json)",
    )
    parser.add_argument(
        "--profile",
        choices=["full", "local", "python"],
        default="python",
        help="Tool profile to run: full (all tools), local (legacy local subset), or python (Python-based models only)",
    )
    parser.add_argument(
        "--strict-model-summaries",
        action="store_true",
        help="Fail model-capable tools if they do not emit a model-generated summary (summary_source=model)",
    )
    parser.add_argument(
        "--gcs-bucket-url",
        type=str,
        default=GCS_BUCKET_URL_PLACEHOLDER,
        help="Google Cloud bucket URL for batch PDF ingestion. Example: gs://your-bucket/path or https://storage.googleapis.com/your-bucket/path",
    )
    parser.add_argument(
        "--gcs-local-dir",
        type=str,
        default="gcs_downloads",
        help="Local directory where bucket PDFs will be downloaded",
    )
    parser.add_argument(
        "--gcs-max-files",
        type=int,
        default=20,
        help="Maximum number of PDFs to download from GCS bucket",
    )
    args = parser.parse_args()

    print("Medical NLP Tools Test Script")
    print("=" * 60)

    text_to_test = SAMPLE_MEDICAL_TEXT
    input_source = "sample_text"

    use_bucket_mode = (
        args.gcs_bucket_url
        and args.gcs_bucket_url.strip()
        and args.gcs_bucket_url.strip() != GCS_BUCKET_URL_PLACEHOLDER
    )

    if use_bucket_mode:
        print(f"Running bucket mode with URL: {args.gcs_bucket_url}")
        output_path = run_bucket_pipeline(
            bucket_url=args.gcs_bucket_url,
            output_file=args.output,
            profile=args.profile,
            strict_model_summaries=args.strict_model_summaries,
            local_dir=args.gcs_local_dir,
            max_files=args.gcs_max_files,
        )
        print(f"\n{'='*60}")
        print(f"Bucket report saved to: {output_path}")
        print(f"{'='*60}\n")
        return []

    if args.input_text_file:
        print(f"Loading text from file: {args.input_text_file}")
        text_to_test = extract_text_from_text_file(args.input_text_file)
        input_source = args.input_text_file
        print(f"Loaded {len(text_to_test)} characters from text file")

    if args.input_pdf:
        print(f"Loading text from PDF: {args.input_pdf}")
        text_to_test = extract_text_from_pdf(args.input_pdf)
        input_source = args.input_pdf
        print(f"Extracted {len(text_to_test)} characters from PDF")
    
    # Test all tools
    results = test_all_tools(
        text_to_test,
        profile=args.profile,
        strict_model_summaries=args.strict_model_summaries,
    )
    
    # Generate report
    report_file = args.output
    generate_report(
        results,
        report_file,
        input_text_length=len(text_to_test),
        input_source=input_source,
    )
    
    # Print summary
    print("\nSummary:")
    print("-" * 60)
    successful = sum(1 for r in results if r['status'] == 'success')
    not_installed = sum(1 for r in results if r['status'] == 'not_installed')
    config_needed = sum(1 for r in results if r['status'] == 'configuration_needed')
    manual_setup = sum(1 for r in results if r['status'] == 'manual_setup_required')
    
    print(f"Successfully tested: {successful}")
    print(f"Not installed: {not_installed}")
    print(f"Configuration needed: {config_needed}")
    print(f"Manual setup required: {manual_setup}")
    print(f"Total tools: {len(results)}")
    
    return results


if __name__ == "__main__":
    results = main()
    sys.exit(0)
